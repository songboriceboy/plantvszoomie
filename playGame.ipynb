{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-abfb13a882e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtrainModel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCatchEnvironment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\deeplearning\\trainModel.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \"\"\"\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from trainModel import CatchEnvironment, X, W1, b1, input_layer, W2, b2, hidden_layer, W3, b3, output_layer, Y, cost, optimizer\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CatchEnvironment' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c794d8795d72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgridSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m  \u001b[1;31m# The size of the grid that the agent is going to play the game on.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmaxGames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCatchEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgridSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mwinCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mloseCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CatchEnvironment' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "gridSize = 10  # The size of the grid that the agent is going to play the game on.\n",
    "maxGames = 100\n",
    "env = CatchEnvironment(gridSize)\n",
    "winCount = 0\n",
    "loseCount = 0\n",
    "numberOfGames = 0\n",
    "modelSaveRoot = os.path.join(os.getcwd(), 'model')\n",
    "savePath = os.path.join(modelSaveRoot, 'model.ckpt')\n",
    "\n",
    "ground = 1\n",
    "plot = pl.figure(figsize=(12, 12))\n",
    "axis = plot.add_subplot(111, aspect='equal')\n",
    "axis.set_xlim(-1, 12)\n",
    "axis.set_ylim(0, 12)\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "def drawState(fruitRow, fruitColumn, basket):\n",
    "    global gridSize\n",
    "    # column is the x axis\n",
    "    fruitX = fruitColumn\n",
    "    # Invert matrix style points to coordinates\n",
    "    fruitY = (gridSize - fruitRow + 1)\n",
    "    statusTitle = \"Wins: \" + str(winCount) + \"  Losses: \" + str(loseCount) + \"  Total: \" + str(numberOfGames)\n",
    "    axis.set_title(statusTitle, fontsize=30)\n",
    "    for p in [\n",
    "        patches.Rectangle(\n",
    "            ((ground - 1), ground), 11, 10,\n",
    "            facecolor=\"#000000\"  # Black\n",
    "        ),\n",
    "        patches.Rectangle(\n",
    "            (basket - 1, ground), 2, 0.5,\n",
    "            facecolor=\"#FFFF33\"  # Yellow\n",
    "        ),\n",
    "        patches.Rectangle(\n",
    "            (fruitX - 0.5, fruitY - 0.5), 1, 1,\n",
    "            facecolor=\"#ff66be\"  # Yellow FFFF33\n",
    "        ),\n",
    "    ]:\n",
    "        axis.add_patch(p)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, savePath)\n",
    "    print('saved model is loaded!')\n",
    "\n",
    "    while numberOfGames < maxGames:\n",
    "        numberOfGames = numberOfGames + 1\n",
    "\n",
    "        # The initial state of the environment.\n",
    "        isGameOver = False\n",
    "        fruitRow, fruitColumn, basket = env.reset()\n",
    "        currentState = env.observe()\n",
    "        drawState(fruitRow, fruitColumn, basket)\n",
    "\n",
    "        while not isGameOver:\n",
    "            # Forward the current state through the network.\n",
    "            q = sess.run(output_layer, feed_dict={X: currentState})\n",
    "            # Find the max index (the chosen action).\n",
    "            index = q.argmax()\n",
    "            action = index + 1\n",
    "            nextState, reward, gameOver, stateInfo = env.act(action)\n",
    "            fruitRow = stateInfo[0]\n",
    "            fruitColumn = stateInfo[1]\n",
    "            basket = stateInfo[2]\n",
    "\n",
    "            # Count game results\n",
    "            if reward == 1:\n",
    "                winCount = winCount + 1\n",
    "            elif reward == -1:\n",
    "                loseCount = loseCount + 1\n",
    "\n",
    "            currentState = nextState\n",
    "            isGameOver = gameOver\n",
    "            drawState(fruitRow, fruitColumn, basket)\n",
    "            time.sleep(0.2)\n",
    "\n",
    "display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
